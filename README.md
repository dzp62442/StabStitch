# <p align="center">Eliminating Warping Shakes for Unsupervised Online Video Stitching

## Introduction
This is the official implementation for [StabStitch](https://arxiv.org/abs/2401.13432) (arXiv 2401.13432).

[Lang Nie](https://nie-lang.github.io/)<sup>1,2</sup>, [Chunyu Lin](https://faculty.bjtu.edu.cn/8549/)<sup>1,2</sup>, [Kang Liao](https://kangliao929.github.io/)<sup>3</sup>, [Yun Zhang](http://zhangyunnet.cn/academic/index.html)<sup>4</sup>, [Shuaicheng Liu](http://www.liushuaicheng.org/)<sup>5</sup>, Rui Ai<sup>6</sup>, [Yao Zhao](https://faculty.bjtu.edu.cn/5900/)<sup>1,2</sup>

<sup>1</sup> Institute of Information Science, Beijing Jiaotong University

<sup>2</sup> Beijing Key Laboratory of Advanced Information Science and Network

<sup>3</sup> Nanyang Technological University

<sup>4</sup> Communication University of Zhejiang 

<sup>5</sup> University of Electronic Science and Technology of China

<sup>6</sup> HAMO.AI

> ### Feature
> This paper tries to implement online video stitching by eliminating warping shakes in a unified unsupervised framework. 
![image](https://github.com/nie-lang/CoupledTPS/blob/main/fig.png)
The above figure shows three examples of our method. The proposed CoupledTPS corrects (a) the 2D in-plane tilt, (b) irregular boundaries, and (c) wide-angle portrait via a unified warping framework.

## Code
We will release the code once the paper is accepted.
